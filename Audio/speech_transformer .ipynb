{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "xjO5BERG0YpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "class SpeechFeatureEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv2 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv3 = tf.keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return self.conv3(x)"
      ],
      "metadata": {
        "id": "FRiJp9pbfO4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):  # Add training argument with default value\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "suqWvJmwfXDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "id": "Gsv6q6mtffc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs, training=False):  # Add training argument with default value\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source, training=training)  # Pass training argument\n",
        "        y = self.decode(x, target)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input], training=True)  # Set training=True\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input], training=False)  # Set training=False\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source, training=False)  # Set training=False\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "id": "TuF6bqopg-RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
        "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
        "    extract=True,\n",
        "    archive_format=\"tar\",\n",
        "    cache_dir=\".\",\n",
        ")\n",
        "\n",
        "\n",
        "saveto = \"./datasets/LJSpeech-1.1\"\n",
        "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
        "\n",
        "id_to_text = {}\n",
        "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        id = line.strip().split(\"|\")[0]\n",
        "        text = line.strip().split(\"|\")[2]\n",
        "        id_to_text[id] = text\n",
        "\n",
        "\n",
        "def get_data(wavs, id_to_text, maxlen=50):\n",
        "    \"\"\" returns mapping of audio paths and transcription texts \"\"\"\n",
        "    data = []\n",
        "    for w in wavs:\n",
        "        id = w.split(\"/\")[-1].split(\".\")[0]\n",
        "        if len(id_to_text[id]) < maxlen:\n",
        "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
        "    return data"
      ],
      "metadata": {
        "id": "5JPrlTqMhJfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26584678-245e-4db2-b3a0-23655bf4dedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "\u001b[1m2748572632/2748572632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorizeChar:\n",
        "    def __init__(self, max_len=50):\n",
        "        self.vocab = (\n",
        "            [\"-\", \"#\", \"<\", \">\"]\n",
        "            + [chr(i + 96) for i in range(1, 27)]\n",
        "            + [\" \", \".\", \",\", \"?\"]\n",
        "        )\n",
        "        self.max_len = max_len\n",
        "        self.char_to_idx = {}\n",
        "        for i, ch in enumerate(self.vocab):\n",
        "            self.char_to_idx[ch] = i\n",
        "\n",
        "    def __call__(self, text):\n",
        "        text = text.lower()\n",
        "        text = text[: self.max_len - 2]\n",
        "        text = \"<\" + text + \">\"\n",
        "        pad_len = self.max_len - len(text)\n",
        "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        return self.vocab\n",
        "\n",
        "\n",
        "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
        "data = get_data(wavs, id_to_text, max_target_len)\n",
        "vectorizer = VectorizeChar(max_target_len)\n",
        "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
        "\n",
        "\n",
        "def create_text_ds(data):\n",
        "    texts = [_[\"text\"] for _ in data]\n",
        "    text_ds = [vectorizer(t) for t in texts]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
        "    return text_ds\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    # spectrogram using stft\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = (x - means) / stddevs\n",
        "    audio_len = tf.shape(x)[0]\n",
        "    # padding to 10 seconds\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_audio_ds(data):\n",
        "    flist = [_[\"audio\"] for _ in data]\n",
        "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
        "    audio_ds = audio_ds.map(\n",
        "        path_to_audio, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return audio_ds\n",
        "\n",
        "\n",
        "def create_tf_dataset(data, bs=4):\n",
        "    audio_ds = create_audio_ds(data)\n",
        "    text_ds = create_text_ds(data)\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "\n",
        "split = int(len(data) * 0.99)\n",
        "train_data = data[:split]\n",
        "test_data = data[split:]\n",
        "ds = create_tf_dataset(train_data, bs=64)\n",
        "val_ds = create_tf_dataset(test_data, bs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuWFXZSihYXf",
        "outputId": "764f9229-8d6f-4e33-b8ff-e11602bffbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayOutputs(keras.callbacks.Callback):\n",
        "    def __init__(\n",
        "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
        "    ):\n",
        "        \"\"\"Displays a batch of outputs after every epoch\n",
        "\n",
        "        Args:\n",
        "            batch: A test batch containing the keys \"source\" and \"target\"\n",
        "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
        "            target_start_token_idx: A start token index in the target vocabulary\n",
        "            target_end_token_idx: An end token index in the target vocabulary\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "        self.target_start_token_idx = target_start_token_idx\n",
        "        self.target_end_token_idx = target_end_token_idx\n",
        "        self.idx_to_char = idx_to_token\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 5 != 0:\n",
        "            return\n",
        "        source = self.batch[\"source\"]\n",
        "        target = self.batch[\"target\"].numpy()\n",
        "        bs = tf.shape(source)[0]\n",
        "        preds = self.model.generate(source, self.target_start_token_idx)\n",
        "        preds = preds.numpy()\n",
        "        for i in range(bs):\n",
        "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
        "            prediction = \"\"\n",
        "            for idx in preds[i, :]:\n",
        "                prediction += self.idx_to_char[idx]\n",
        "                if idx == self.target_end_token_idx:\n",
        "                    break\n",
        "            print(f\"target:     {target_text.replace('-','')}\")\n",
        "            print(f\"prediction: {prediction}\\n\")"
      ],
      "metadata": {
        "id": "R2LLfqQKhlc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        init_lr=0.00001,\n",
        "        lr_after_warmup=0.001,\n",
        "        final_lr=0.00001,\n",
        "        warmup_epochs=15,\n",
        "        decay_epochs=85,\n",
        "        steps_per_epoch=203,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_after_warmup = lr_after_warmup\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.decay_epochs = decay_epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "    def calculate_lr(self, epoch):\n",
        "        \"\"\"Linear warmup - linear decay.\"\"\"\n",
        "        epoch = tf.cast(epoch, tf.float32)\n",
        "        warmup_lr = self.init_lr + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
        "        decay_lr = tf.math.maximum(\n",
        "            self.final_lr,\n",
        "            self.lr_after_warmup - (epoch - self.warmup_epochs) * (self.lr_after_warmup - self.final_lr) / self.decay_epochs,\n",
        "        )\n",
        "        return tf.math.minimum(warmup_lr, decay_lr)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        epoch = step // self.steps_per_epoch\n",
        "        epoch = tf.cast(epoch, tf.int32)\n",
        "        return self.calculate_lr(epoch)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Returns the configuration of the learning rate schedule.\"\"\"\n",
        "        return {\n",
        "            \"init_lr\": self.init_lr,\n",
        "            \"lr_after_warmup\": self.lr_after_warmup,\n",
        "            \"final_lr\": self.final_lr,\n",
        "            \"warmup_epochs\": self.warmup_epochs,\n",
        "            \"decay_epochs\": self.decay_epochs,\n",
        "            \"steps_per_epoch\": self.steps_per_epoch,\n",
        "        }"
      ],
      "metadata": {
        "id": "vV-IL-BKhvap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(val_ds))\n",
        "\n",
        "# The vocabulary to convert predicted indices into characters\n",
        "idx_to_char = vectorizer.get_vocabulary()\n",
        "display_cb = DisplayOutputs(\n",
        "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
        ")  # set the arguments as per vocabulary index for '<' and '>'\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=4,\n",
        "    num_feed_forward=400,\n",
        "    target_maxlen=max_target_len,\n",
        "    num_layers_enc=4,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=34,\n",
        ")\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=True, label_smoothing=0.1,\n",
        ")\n",
        "\n",
        "learning_rate = CustomSchedule(\n",
        "    init_lr=0.00001,\n",
        "    lr_after_warmup=0.001,\n",
        "    final_lr=0.00001,\n",
        "    warmup_epochs=15,\n",
        "    decay_epochs=85,\n",
        "    steps_per_epoch=len(ds),\n",
        ")\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n"
      ],
      "metadata": {
        "id": "nKrobAk3h1TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"best_model.keras\",  # Use .keras extension\n",
        "    monitor=\"val_loss\",           # Metric to monitor (validation loss)\n",
        "    save_best_only=True,          # Save only the best model\n",
        "    mode=\"min\",                   # Minimize the monitored metric\n",
        "    verbose=1                     # Print a message when saving the model\n",
        ")\n",
        "\n",
        "# Add the checkpoint callback to the list of callbacks\n",
        "callbacks = [display_cb, checkpoint_callback]\n",
        "\n",
        "# Train the model with the checkpoint callback\n",
        "history = model.fit(\n",
        "    ds,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks,\n",
        "    epochs=50  # Adjust the number of epochs as needed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwzASjZoVtrd",
        "outputId": "016dad8b-8b8d-4ce6-db2c-b00368fc6e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'speech_feature_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:617: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728ms/step - loss: 1.8295"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (4, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target:     <i believe with abraham lincoln, that #the legitimate object of government is to do for a community of people>\n",
            "prediction: <the e the t are t the athe t a anton to t athe t athe the an on the athe the the ton the t the as t he con t the the at t t as the e on ofon s ase o t inere thin atome o at t arind at int tond he ter\n",
            "\n",
            "target:     <it was thought that capital punishment would lose its deterrent effect if it ceased to be public,>\n",
            "prediction: <the e the t are t the athe t a anton to t athe t athe the an on the athe the the ton the t the as t he con t the the ate the s the e on ofon s ase o t inere thin atome o at t arind at int tond he ter\n",
            "\n",
            "target:     <it is essentially a fish, and would be so classed if it remained in this condition.>\n",
            "prediction: <the e the t are t the athe t a anton to t athe t athe the an on the athe the the ton the t the as t he con t the the ate the s the e on onthe oise o t inere thin atome o at t arind at int tond he ter\n",
            "\n",
            "target:     <smethurst was found guilty by the jury, and sentenced to death.>\n",
            "prediction: <the e the t are t the athe t a anton to t athe t athe the an on the athe the the ton the t the as t he con t the the ate the s the e on onthe oine o t inere thin atome o at t arind at int tond he ter\n",
            "\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.42016, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 816ms/step - loss: 1.8287 - val_loss: 1.4202\n",
            "Epoch 2/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - loss: 1.4146\n",
            "Epoch 2: val_loss improved from 1.42016 to 1.28641, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 646ms/step - loss: 1.4144 - val_loss: 1.2864\n",
            "Epoch 3/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - loss: 1.3403\n",
            "Epoch 3: val_loss improved from 1.28641 to 1.26491, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 643ms/step - loss: 1.3402 - val_loss: 1.2649\n",
            "Epoch 4/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633ms/step - loss: 1.3210\n",
            "Epoch 4: val_loss improved from 1.26491 to 1.25659, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 642ms/step - loss: 1.3210 - val_loss: 1.2566\n",
            "Epoch 5/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - loss: 1.3095\n",
            "Epoch 5: val_loss improved from 1.25659 to 1.24169, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 646ms/step - loss: 1.3094 - val_loss: 1.2417\n",
            "Epoch 6/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - loss: 1.2912target:     <i believe with abraham lincoln, that #the legitimate object of government is to do for a community of people>\n",
            "prediction: <and the the fof the the the the the the the the the athe athe the the f the f f the the f the are foure the f the the the the the the are the.>\n",
            "\n",
            "target:     <it was thought that capital punishment would lose its deterrent effect if it ceased to be public,>\n",
            "prediction: <the she she fisthe fiche sthe the she sthe she athe athe s she f she f fiche she athe fiche the athe she the she athe the the the the.>\n",
            "\n",
            "target:     <it is essentially a fish, and would be so classed if it remained in this condition.>\n",
            "prediction: <the sustin as fin the the fisthe asin asin the an f an an fin the the fin fin f f the fine the fishe asin.>\n",
            "\n",
            "target:     <smethurst was found guilty by the jury, and sentenced to death.>\n",
            "prediction: <senthe the se sere the the the the se se the se the the se sere the the the the the the se the there theafinthe.>\n",
            "\n",
            "\n",
            "Epoch 6: val_loss improved from 1.24169 to 1.21972, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 682ms/step - loss: 1.2911 - val_loss: 1.2197\n",
            "Epoch 7/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640ms/step - loss: 1.2606\n",
            "Epoch 7: val_loss improved from 1.21972 to 1.16535, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 647ms/step - loss: 1.2605 - val_loss: 1.1654\n",
            "Epoch 8/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640ms/step - loss: 1.2050\n",
            "Epoch 8: val_loss improved from 1.16535 to 1.09077, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 647ms/step - loss: 1.2049 - val_loss: 1.0908\n",
            "Epoch 9/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - loss: 1.1168\n",
            "Epoch 9: val_loss improved from 1.09077 to 0.96004, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 646ms/step - loss: 1.1166 - val_loss: 0.9600\n",
            "Epoch 10/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638ms/step - loss: 0.9876\n",
            "Epoch 10: val_loss improved from 0.96004 to 0.82407, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 653ms/step - loss: 0.9874 - val_loss: 0.8241\n",
            "Epoch 11/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - loss: 0.8738target:     <i believe with abraham lincoln, that #the legitimate object of government is to do for a community of people>\n",
            "prediction: <i the lead hime led agant of pead of pead of pead of pead of pead of peadect of pead of pead of pead of pead of pead of pead ouctimmmmmmme>\n",
            "\n",
            "target:     <it was thought that capital punishment would lose its deterrent effect if it ceased to be public,>\n",
            "prediction: <it would that capent would losed to be lock that the capent would look, posed to be lock,>\n",
            "\n",
            "target:     <it is essentially a fish, and would be so classed if it remained in this condition.>\n",
            "prediction: <it is the sencention the sen the sen iffich and in the sencence and in thish, and would be asshily as condition.>\n",
            "\n",
            "target:     <smethurst was found guilty by the jury, and sentenced to death.>\n",
            "prediction: <sent sent sentence to deat deat intence to deat deat found to death.>\n",
            "\n",
            "\n",
            "Epoch 11: val_loss improved from 0.82407 to 0.74977, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 677ms/step - loss: 0.8737 - val_loss: 0.7498\n",
            "Epoch 12/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - loss: 0.8030\n",
            "Epoch 12: val_loss improved from 0.74977 to 0.71687, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 642ms/step - loss: 0.8029 - val_loss: 0.7169\n",
            "Epoch 13/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - loss: 0.7532\n",
            "Epoch 13: val_loss improved from 0.71687 to 0.67427, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 641ms/step - loss: 0.7531 - val_loss: 0.6743\n",
            "Epoch 14/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633ms/step - loss: 0.7162\n",
            "Epoch 14: val_loss improved from 0.67427 to 0.65326, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 642ms/step - loss: 0.7161 - val_loss: 0.6533\n",
            "Epoch 15/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - loss: 0.6873\n",
            "Epoch 15: val_loss improved from 0.65326 to 0.62394, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 627ms/step - loss: 0.6873 - val_loss: 0.6239\n",
            "Epoch 16/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step - loss: 0.6476target:     <i believe with abraham lincoln, that #the legitimate object of government is to do for a community of people>\n",
            "prediction: <i gengent the leadgain the lead ject of government is to do do f government is to do do f government is to do do f government the gof of of of>\n",
            "\n",
            "target:     <it was thought that capital punishment would lose its deterrent effect if it ceased to be public,>\n",
            "prediction: <it a sthought the capital punishment would loose it sthought the capital punishment would loose it seased to be punishment would>\n",
            "\n",
            "target:     <it is essentially a fish, and would be so classed if it remained in this condition.>\n",
            "prediction: <it is the so cleast is the sention.>\n",
            "\n",
            "target:     <smethurst was found guilty by the jury, and sentenced to death.>\n",
            "prediction: <sentenced to deathers faund gilty by the jury, and sentenced to death.>\n",
            "\n",
            "\n",
            "Epoch 16: val_loss improved from 0.62394 to 0.58771, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 664ms/step - loss: 0.6476 - val_loss: 0.5877\n",
            "Epoch 17/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - loss: 0.6136\n",
            "Epoch 17: val_loss improved from 0.58771 to 0.55963, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 631ms/step - loss: 0.6135 - val_loss: 0.5596\n",
            "Epoch 18/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - loss: 0.5826\n",
            "Epoch 18: val_loss improved from 0.55963 to 0.54808, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 631ms/step - loss: 0.5826 - val_loss: 0.5481\n",
            "Epoch 19/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - loss: 0.5605\n",
            "Epoch 19: val_loss improved from 0.54808 to 0.52662, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 627ms/step - loss: 0.5604 - val_loss: 0.5266\n",
            "Epoch 20/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - loss: 0.5413\n",
            "Epoch 20: val_loss improved from 0.52662 to 0.51664, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 626ms/step - loss: 0.5413 - val_loss: 0.5166\n",
            "Epoch 21/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - loss: 0.5372target:     <i believe with abraham lincoln, that #the legitimate object of government is to do for a community of people>\n",
            "prediction: <i bet the led ject o do do opked o ject of people bople bornment the le ave with abre ham linkant of people,>\n",
            "\n",
            "target:     <it was thought that capital punishment would lose its deterrent effect if it ceased to be public,>\n",
            "prediction: <et was thought that capital punishment would lose it seased to be punishment would loose it seased to be punishment would look.>\n",
            "\n",
            "target:     <it is essentially a fish, and would be so classed if it remained in this condition.>\n",
            "prediction: <it is the centially affishe, and would be so cles o cles o clest if remained in this centially affishe.>\n",
            "\n",
            "target:     <smethurst was found guilty by the jury, and sentenced to death.>\n",
            "prediction: <smetterst was found gilty by the jury and sentenced to death.>\n",
            "\n",
            "\n",
            "Epoch 21: val_loss improved from 0.51664 to 0.50768, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 666ms/step - loss: 0.5372 - val_loss: 0.5077\n",
            "Epoch 22/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step - loss: 0.5174\n",
            "Epoch 22: val_loss improved from 0.50768 to 0.49945, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 637ms/step - loss: 0.5174 - val_loss: 0.4995\n",
            "Epoch 23/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - loss: 0.5037\n",
            "Epoch 23: val_loss improved from 0.49945 to 0.49373, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 639ms/step - loss: 0.5037 - val_loss: 0.4937\n",
            "Epoch 24/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - loss: 0.4940\n",
            "Epoch 24: val_loss improved from 0.49373 to 0.48933, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 638ms/step - loss: 0.4940 - val_loss: 0.4893\n",
            "Epoch 25/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - loss: 0.4825\n",
            "Epoch 25: val_loss improved from 0.48933 to 0.48147, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 637ms/step - loss: 0.4825 - val_loss: 0.4815\n",
            "Epoch 26/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - loss: 0.4717target:     <i believe with abraham lincoln, that #the legitimate object of government is to do for a community of people>\n",
            "prediction: <i bet is to do af government that the le evewith a brehm linken, government that the land ject of government t of people>\n",
            "\n",
            "target:     <it was thought that capital punishment would lose its deterrent effect if it ceased to be public,>\n",
            "prediction: <it was thought that capitarint effect ifict to be punishment would lose its diter effect ifict if ath capital punishment would lik,>\n",
            "\n",
            "target:     <it is essentially a fish, and would be so classed if it remained in this condition.>\n",
            "prediction: <it is the sentially offeish, and would beso condition.>\n",
            "\n",
            "target:     <smethurst was found guilty by the jury, and sentenced to death.>\n",
            "prediction: <smetherst was found guilty by the dury, and sentenced to death.>\n",
            "\n",
            "\n",
            "Epoch 26: val_loss improved from 0.48147 to 0.47220, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 670ms/step - loss: 0.4717 - val_loss: 0.4722\n",
            "Epoch 27/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step - loss: 0.4637\n",
            "Epoch 27: val_loss improved from 0.47220 to 0.46699, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 637ms/step - loss: 0.4637 - val_loss: 0.4670\n",
            "Epoch 28/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - loss: 0.4675\n",
            "Epoch 28: val_loss did not improve from 0.46699\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 634ms/step - loss: 0.4675 - val_loss: 0.4684\n",
            "Epoch 29/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step - loss: 0.4588\n",
            "Epoch 29: val_loss improved from 0.46699 to 0.46056, saving model to best_model.keras\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 633ms/step - loss: 0.4588 - val_loss: 0.4606\n",
            "Epoch 30/50\n",
            "\u001b[1m 56/203\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 628ms/step - loss: 0.4501"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer\n",
        "import jiwer\n",
        "import numpy as np\n",
        "\n",
        "def calculate_wer_cer(model, dataset, vectorizer):\n",
        "    \"\"\"\n",
        "    Calculate Word Error Rate (WER) and Character Error Rate (CER) for a given dataset.\n",
        "    \"\"\"\n",
        "    wer_scores = []\n",
        "    cer_scores = []\n",
        "\n",
        "    for batch in dataset:\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"].numpy()\n",
        "\n",
        "        # Generate predictions\n",
        "        preds = model.generate(source, target_start_token_idx=2)  # Start token index\n",
        "        preds = preds.numpy()\n",
        "\n",
        "        # Convert predictions and targets to text\n",
        "        for i in range(len(target)):\n",
        "            target_text = \"\".join([vectorizer.get_vocabulary()[idx] for idx in target[i] if idx != 0])\n",
        "            pred_text = \"\".join([vectorizer.get_vocabulary()[idx] for idx in preds[i] if idx != 0])\n",
        "\n",
        "            # Calculate WER and CER\n",
        "            wer = jiwer.wer(target_text, pred_text)\n",
        "            cer = jiwer.cer(target_text, pred_text)\n",
        "\n",
        "            wer_scores.append(wer)\n",
        "            cer_scores.append(cer)\n",
        "\n",
        "    # Compute average WER and CER\n",
        "    avg_wer = np.mean(wer_scores)\n",
        "    avg_cer = np.mean(cer_scores)\n",
        "\n",
        "    return avg_wer, avg_cer\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "avg_wer, avg_cer = calculate_wer_cer(model, val_ds, vectorizer)\n",
        "print(f\"Validation WER: {avg_wer:.4f}, Validation CER: {avg_cer:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De-Ce4vVXmdW",
        "outputId": "1ddd1c88-9ed5-456b-abd8-f8ef7e425251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.0.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.11.0)\n",
            "Validation WER: 1.0352, Validation CER: 1.6234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_audio(model, audio_path, vectorizer, target_start_token_idx=2):\n",
        "    \"\"\"\n",
        "    Generate a prediction for a single audio file.\n",
        "    \"\"\"\n",
        "    # Convert the audio file to a spectrogram\n",
        "    spectrogram = path_to_audio(audio_path)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Generate the prediction\n",
        "    preds = model.generate(spectrogram, target_start_token_idx)\n",
        "    preds = preds.numpy()\n",
        "\n",
        "    # Convert the prediction to text\n",
        "    pred_text = \"\".join([vectorizer.get_vocabulary()[idx] for idx in preds[0] if idx != 0])\n",
        "    return pred_text\n",
        "\n",
        "# Test the model on a new audio file\n",
        "audio_path = \"/content/datasets/LJSpeech-1.1/wavs/LJ001-0001.wav\"  # Replace with the path to your audio file\n",
        "prediction = predict_from_audio(model, audio_path, vectorizer)\n",
        "print(f\"Predicted Text: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba4UWKUyWFQO",
        "outputId": "cfedb851-f325-4ccf-9534-27dcce948156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Text: <printing in the only sand conceraft from all the arts inceraft since with which which we artsince with which we artsibition>>>> in the arts siprentincesincion>ipipren>ion>>in>enneditepresehemthexonot\n"
          ]
        }
      ]
    }
  ]
}
